{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name:\n",
    "#### Student ID:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 190 Assignment 1\n",
    "\n",
    "### Mozart Dice Game, Fourier Transforms, Spectrograms, and Griffin-Lim Phase Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: \n",
    "\n",
    "This notebook is an interactive assignment; please read and follow the instructions in each cell.\n",
    "\n",
    "Assignments are to be completed individually.\n",
    "\n",
    "Cells that require your input (in the form of code or written response) will have 'Question #' above.\n",
    "\n",
    "After completing the assignment, please submit this notebook as a PDF and your Mozart Dice Game MIDI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mozart Dice Game\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section of the assignment, you will implement the Mozart Dice Game using MIDI. \n",
    "\n",
    "Your composition will be a 16-measure minuet using 'dice rolls' (random generation in Python). \n",
    "\n",
    "Please check out the interactive demo available here (http://www.playonlinedicegames.com/mozart). \n",
    "\n",
    "Please see the code in the cell below for an example of combining MIDI files together (since you will be combining musical cells to create your Mozart Dice Game composition). You may want to install MIT's music21 python library (http://web.mit.edu/music21/) using pip. If you would rather combine MIDI files with another method, feel free to explore. \n",
    "\n",
    "The MIDI files, created by Packard Humanities Institute's Center for Computer Assisted Research in the Humanities at Stanford University, can be found in a .zip archive in the assignment repository. \n",
    "\n",
    "The code cell below also contains the filenames of candidate phrases for each of the 16 measures of your Mozart Dice Menuet (A1-B8). Using a random 'dice roll,' you will select one of the candidates for that measure of your minuet. The final product is the stitched-together combination of all 16 measures, selected via dice roll. \n",
    "\n",
    "Please save a .midi file of your randomly generated minuet to submit to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import midi as midi21\n",
    "from music21 import stream\n",
    "import copy\n",
    "import music21\n",
    "\n",
    "def play(x):\n",
    "    \"\"\"Returns nothing. Outputs a midi realization of x, a note or stream.\n",
    "    Primarily for use in notebooks and web environments.\n",
    "    \"\"\"  \n",
    "    if isinstance(x, stream.Stream):\n",
    "        x = copy.deepcopy(x)\n",
    "        for subStream in x.recurse(streamsOnly=True, includeSelf=True):\n",
    "            mss = subStream.getElementsByClass(stream.Measure)\n",
    "            for ms in mss:\n",
    "                ms.offset += 1.0\n",
    "    if isinstance(x, music21.note.Note):\n",
    "        s = stream.Stream()\n",
    "        s.append(music21.note.Rest(1))\n",
    "        s.append(x)\n",
    "        x = s\n",
    "    x.show('midi')\n",
    "\n",
    "mf1 = midi21.MidiFile()\n",
    "mf1.open(\"mozartdicegame/cda001.mid\")\n",
    "mf1.read()\n",
    "mf1.close()\n",
    "s1 = midi21.translate.midiFileToStream(mf1)\n",
    "\n",
    "mf2 = midi21.MidiFile()\n",
    "mf2.open(\"mozartdicegame/cda002.mid\")\n",
    "mf2.read()\n",
    "mf2.close()\n",
    "s2 = midi21.translate.midiFileToStream(mf2)\n",
    "\n",
    "myStream = stream.Stream()\n",
    "myStream.append(s1)\n",
    "myStream.append(s2)\n",
    "play(myStream)\n",
    "myStream.write('midi', fp='combined_midi.mid')\n",
    "\n",
    "\n",
    "A1 = \"070 010 033 036 105 165 007 142 099 085 145\"\n",
    "A2 = \"014 064 001 114 150 152 081 106 068 045 097\"\n",
    "A3 = \"164 100 160 008 057 112 131 040 086 090 006\"\n",
    "A4 = \"122 012 163 035 071 015 037 069 139 158 121\"\n",
    "A5 = \"025 149 077 111 117 147 021 043 120 082 056\"\n",
    "A6 = \"153 030 156 039 052 027 125 140 092 123 067\"\n",
    "A7 = \"018 161 168 137 132 073 049 023 143 078 063\" \n",
    "A8 = \"167 011 172 044 130 102 115 089 083 058 016\"\n",
    "\n",
    "B1 = \"155 148 022 004 136 144 116 066 093 061 050\"\n",
    "B2 = \"003 028 176 157 091 104 133 124 055 034 079\" \n",
    "B3 = \"162 135 062 038 138 087 072 026 029 119 175\" \n",
    "B4 = \"170 173 126 009 019 107 141 084 051 046 076\" \n",
    "B5 = \"013 169 031 151 134 128 094 075 042 059 113\" \n",
    "B6 = \"166 174 024 032 101 048 080 103 110 054 088\" \n",
    "B7 = \"095 002 159 017 154 109 129 096 108 060 053\" \n",
    "B8 = \"005 020 041 171 146 074 065 127 098 047 118\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1 (Including Output MIDI) [15 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Mozart Dice Game implementation here:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Transform\n",
    "--------------\n",
    "\n",
    "The Discrete Fourier Transform (DFT) is the primary analysis tool for digital signal processing. By using matrix/vector representation, the DFT can be understood as a transformation of digital signals into a new vector space.\n",
    "\n",
    "In this space  the columns of the DFT are the basis vectors. One important idea is that we call these vectors as \"frequencies\", but mathematically they simply represent the original data in a different space.\n",
    "\n",
    "This is the mathematical definition of DFT matrix\n",
    "\n",
    "$$ \\mathbf{U} = \\frac{1}{\\sqrt N} \\left[ \\exp \\left( j \\frac{2\\pi}{N} n k \\right) \\right]_{n\\in\\{0,N_s-1\\},k\\in\\{0,N-1\\}} $$\n",
    "\n",
    "\n",
    "where $n$ counts the samples as rows and $k$ indexes the discrete frequencies (which are our new basis) as columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2 [15 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import  division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import librosa\n",
    "%matplotlib inline\n",
    "import IPython.display as ipydisplay\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "def dftmatrix(Nfft=32,N=None):\n",
    "    'construct DFT matrix'\n",
    "    k= np.arange(Nfft)\n",
    "    if N is None: N = Nfft\n",
    "    n = np.arange(N)\n",
    "    \n",
    "    ### Implement the DFT matrix (U) here\n",
    "\n",
    "    \n",
    "    return U/np.sqrt(Nfft)\n",
    "\n",
    "Nfft=8\n",
    "Ns=8\n",
    "U = dftmatrix(Nfft=Nfft,N=Ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot these basis as pairs of real and imaginary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20, 16)\n",
    "\n",
    "# plots in the left column\n",
    "plt.subplot(Nfft,2,1)\n",
    "plt.title('Real Part',fontsize=24)\n",
    "\n",
    "for i in range(Nfft):\n",
    "    plt.subplot(Nfft,2,2*i+1)\n",
    "    plt.xticks([]);  plt.yticks([])\n",
    "    plt.ylabel(r'$\\Omega_{%d}=%d\\times\\frac{2\\pi}{16}$'%(i,i),fontsize=24, \n",
    "        rotation='horizontal',horizontalalignment='right')\n",
    "    plt.plot(np.array(U.real[:,i]),'-o')\n",
    "    plt.axis(ymax=4/Nfft*1.1,ymin=-4/Nfft*1.1)\n",
    "plt.xticks(np.arange(Nfft))\n",
    "plt.xlabel('n')\n",
    "\n",
    "# plots in the  right column\n",
    "plt.subplot(Nfft,2,2)\n",
    "plt.title('Imaginary Part',fontsize=24)\n",
    "\n",
    "for i in range(Nfft):\n",
    "    ax=plt.subplot(Nfft,2,2*(i+1))\n",
    "    plt.xticks([]);  plt.yticks([])\n",
    "    plt.plot(np.array(U.imag[:,i]),'--o')\n",
    "    plt.axis(ymax=4/Nfft*1.1,ymin=-4/Nfft*1.1)    \n",
    "plt.xticks(np.arange(Nfft))\n",
    "plt.xlabel('n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3 [5 points]\n",
    "\n",
    "What do you observe in the above plots, considering symmetries and the relationship between real & imaginary parts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Your response here``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the DFT\n",
    "--------------------\n",
    "\n",
    "To compute the DFT using the matrix, we calculate the following,\n",
    "\n",
    "$$ \\mathbf{X} = \\mathbf{U}^H \\mathbf{x}$$\n",
    "\n",
    "which individually takes each of the columns of $\\mathbf{U}$ and computes the inner product as the $i^{th}$ entry,\n",
    "\n",
    "$$ \\mathbf{X}_i = \\mathbf{U}_i^H \\mathbf{x}$$\n",
    "\n",
    "That is, we are measuring the *degree of similarity* between each column of $\\mathbf{U}$ and the input vector. We can think of this as the coefficient of the projection of $\\mathbf{x}$ onto  $\\mathbf{u}_i$.\n",
    "\n",
    "We can retrieve the original input from the DFT by calculating\n",
    "\n",
    "$$ \\mathbf{x} = \\mathbf{U} \\mathbf{U}^H \\mathbf{X} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: finding a frequency of a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "\n",
    "Ns = 70\n",
    "freq = 5.5/Ns\n",
    "t = np.arange(Ns)\n",
    "x = np.sin(2*np.pi*freq*t)\n",
    "plt.plot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4 [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nfft = Ns\n",
    "U = dftmatrix(Nfft=Nfft,N=Ns)\n",
    "x = np.matrix(x)\n",
    "\n",
    "### Compute X, the DFT of signal x\n",
    "\n",
    "\n",
    "\n",
    "plt.stem(np.array(abs(X)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5 [5 points]\n",
    "\n",
    "Where do you observe peaks in the DFT plot? How would you describe the DFT plot symmetry? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Your response here``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing Sound Using Spectrograms\n",
    "\n",
    "For this portion of the assignment, you will have the chance to see your own voice!\n",
    "First, make two recordings of yourself:\n",
    "\n",
    "In the first recording, you will say a vowel sound of your choice (\"ah\", \"ee\", \"oo\", etc.). Try to keep the sound short (no longer than you would make the vowel sound in a typical word (\"car\", \"see\", \"good\"). \n",
    "\n",
    "In the second recording, sing (or play on an instrument) any major scale, at a tempo of 60 bpm. (Don't worry, it doesn't need to be perfect- your best effort will be great!). \n",
    "\n",
    "Make sure both of your recordings are saved as mono WAV files. Audacity is a great tool to quickly convert audio file formats (and convert from stereo to mono). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_graph(title='', x_label='', y_label='', fig_size=None):\n",
    "    fig = plt.figure()\n",
    "    if fig_size != None:\n",
    "        fig.set_size_inches(fig_size[0], fig_size[1])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modify the line below with your WAV file:\n",
    "sample_rate, input_signal = wavfile.read(\"PATH_TO_YOUR_MONO_WAV_FILE.wav\")\n",
    "time_array = np.arange(0, len(input_signal)/sample_rate, 1/sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_graph(title='Ah vowel sound', x_label='time (in seconds)', y_label='amplitude', fig_size=(14,7))\n",
    "_ = plt.plot(time_array[0:4000], input_signal[0:4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 7 [5 points]\n",
    "\n",
    "The FFT of your input signal is complex valued (real and imaginary components). \n",
    "To visualize the output of the FFT of your input signal, we will calculate the magnitude of the FFT output.\n",
    "In your code, you may want to make use of the .real and .imag members of the numpy complex128 class as you explore the fft_out datatype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_out = np.fft.rfft(input_signal)\n",
    "\n",
    "fft_mag = ''' Your Code Here'''\n",
    "\n",
    "num_samples = len(input_signal)\n",
    "rfreqs = [(i*1.0/num_samples)*sample_rate for i in range(num_samples//2+1)]\n",
    "setup_graph(title='FFT of Vowel (first 5000)', x_label='FFT Bins', y_label='magnitude', fig_size=(14,7))\n",
    "_ = plt.plot(rfreqs[0:5000], fft_mag[0:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 8 [5 points]\n",
    "\n",
    "Would you expect another person's recording of the same vowel sound (on the same pitch and at the same volume) to have a similar FFT graph? What musical term is used to describe this quality? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram (FFT over time)\n",
    "\n",
    "### Axes\n",
    "\n",
    "* x-axis: time\n",
    "* y-axis: frequency\n",
    "* z-axis (color): strength of each frequency\n",
    "\n",
    "### See the Harmonics!\n",
    "\n",
    "##### Question 9 [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modify the line below:\n",
    "sample_rate, sample = wavfile.read(\"YOUR_SCALE_MONO_WAV_FILE.wav\")\n",
    "\n",
    "setup_graph(title='Spectrogram of diatonic scale (%dHz sample rate)' % sample_rate, x_label='time (in seconds)', y_label='frequency', fig_size=(14,8))\n",
    "_ = plt.specgram(sample, Fs=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_8000hz = [sample[i] for i in range(0, len(sample), sample_rate//8000)]\n",
    "setup_graph(title='Spectrogram (8000Hz sample rate)', x_label='time (in seconds)', y_label='frequency', fig_size=(14,7))\n",
    "_ = plt.specgram(sample_8000hz, Fs=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_4000hz = [sample[i] for i in range(0, len(sample), sample_rate//4000)]\n",
    "setup_graph(title='Spectrogram (4000Hz sample rate)', x_label='time (in seconds)', y_label='frequency', fig_size=(14,7))\n",
    "_ = plt.specgram(sample_4000hz, Fs=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 10 [5 points]\n",
    "\n",
    "In your recording, you were singing (or playing) a single note at a time. Does this still appear to be the case when looking at the spectrogram of your recording? What are you observing? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 11 [5 points]\n",
    "\n",
    "What would you expect the relationship between the first and last note on your spectrogram to be? Is this the case?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram inversion from spectral amplitude\n",
    "\n",
    "Short-time Fourier Transform (STFT) analysis takes short snapshots of sound and represents them as a matrix of fft vectors.\n",
    "As we saw above, the fft is a complex transform that contain information about amplitude and phase of each frequency component. In many applications we choose to discard the phases and use the amplitudes only. \n",
    "\n",
    "One challenge is to reconstruct the original waveform from amplitude information only.\n",
    "\n",
    "For these questions, we will explore an iterative method by Griffin and Lim.\n",
    "\n",
    "Let's start with creating spectral amplitudes of your earlier vowel WAV file:\n",
    "\n",
    "##### Question 12 [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads wav file and produces spectrum\n",
    "# Fourier phases are ignored\n",
    "\n",
    "def wave_to_spectum(x, n_fft):\n",
    "    S = librosa.stft(x, n_fft)\n",
    "    p = np.angle(S)   \n",
    "    A = np.log1p(np.abs(S))  \n",
    "    return A\n",
    "\n",
    "### Replace the string below with your file:\n",
    "filename = 'YOUR_WAV_FILE_HERE'\n",
    "x, fs = librosa.load(filename)\n",
    "n_fft = 2048\n",
    "plt.plot(x)\n",
    "SA = wave_to_spectum(x, n_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipydisplay.Audio(data=x, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(SA[:400,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Griffin and Lim method\n",
    "\n",
    "In the next code block, you will implement the Griffin and Lim iterative method for phase reconstruction.\n",
    "Please look over the pseudocode available on pg. 1865 of Wakabayashi & Ono's 2019 paper, available at http://www.apsipa.org/proceedings/2019/pdfs/290.pdf\n",
    "\n",
    "The random phase initialization is provided as p. Please use 1000 iterations for your reconstruction. \n",
    "\n",
    "You may find the librosa functions istft and stft helpful in your implementation. \n",
    "\n",
    "##### Question 13 [15 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spectrum_wav(a, N_FFT):\n",
    "    # Given input amplitude a, return reconstructed signal x using the Griffin & Lim iterative method. \n",
    "    p = 2 * np.pi * np.random.random_sample(a.shape) - np.pi\n",
    "    '''\n",
    "    YOUR IMPLEMENTATION HERE\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "x_out = write_spectrum_wav(SA, n_fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare your reconstruction to the original signal, both auditorily and visually: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILENAME = 'out.wav'\n",
    "librosa.output.write_wav(OUTPUT_FILENAME, x_out, fs)\n",
    "display(Audio(OUTPUT_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[:1000])\n",
    "plt.plot(x_out[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Griffin and Lim method is not a perfect reconstruction.\n",
    "Let's compare this to directly inverting the complex specta from STFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.stft(x, n_fft)\n",
    "x_inv = librosa.istft(S, win_length=n_fft)\n",
    "plt.plot(x[:1000])\n",
    "plt.plot(x_inv[:1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
